<!doctype html>



  


<html class="theme-next pisces use-motion">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">












  
  
  <link href="/VEN/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/VEN/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.0.2" rel="stylesheet" type="text/css">


  <meta name="keywords" content="Reinforcement Learning,">








  <link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico?v=5.0.2">






<meta name="description" content="Importance Sampling1.What is Importance SamplingImportance Sampling(IS) is a general technique for estimating properties of a particular distribution $p$, while only having samples generated from a di">
<meta name="keywords" content="Reinforcement Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="RL_Importance_Sampling">
<meta property="og:url" content="http://huixxi.github.io/2020/05/26/RL-Importance-Sampling/index.html">
<meta property="og:site_name" content="HU">
<meta property="og:description" content="Importance Sampling1.What is Importance SamplingImportance Sampling(IS) is a general technique for estimating properties of a particular distribution $p$, while only having samples generated from a di">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://raw.githubusercontent.com/Huixxi/TensorFlow2.0-for-Deep-Reinforcement-Learning/master/images/rlblog_images/IS.jpg">
<meta property="og:updated_time" content="2020-06-04T07:16:39.727Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="RL_Importance_Sampling">
<meta name="twitter:description" content="Importance Sampling1.What is Importance SamplingImportance Sampling(IS) is a general technique for estimating properties of a particular distribution $p$, while only having samples generated from a di">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Huixxi/TensorFlow2.0-for-Deep-Reinforcement-Learning/master/images/rlblog_images/IS.jpg">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    }
  };
</script>




  <link rel="canonical" href="http://huixxi.github.io/2020/05/26/RL-Importance-Sampling/">


  <title> RL_Importance_Sampling | HU </title>
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">HU</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">\&</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                RL_Importance_Sampling
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2020-05-26T14:18:33+08:00" content="2020-05-26">
              2020-05-26
            </time>
          </span>

          
            <span class="post-category">
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Math/" itemprop="url" rel="index">
                    <span itemprop="name">Math</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2020/05/26/RL-Importance-Sampling/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/05/26/RL-Importance-Sampling/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="Importance-Sampling"><a href="#Importance-Sampling" class="headerlink" title="Importance Sampling"></a>Importance Sampling</h2><h4 id="1-What-is-Importance-Sampling"><a href="#1-What-is-Importance-Sampling" class="headerlink" title="1.What is Importance Sampling"></a>1.What is Importance Sampling</h4><p><strong>Importance Sampling(IS)</strong> is a general technique for estimating properties of a particular distribution $p$, while only having samples generated from a different distribution $q$ than the distribution of interest($p$). </p>
<p>And actually, <strong>IS</strong> is a variant of <strong>Monte Carlo approximation</strong>.  In Monte Carlo approximation, we were extimating the expected value of a random variable $X$ by this sample mean sum: </p>
<script type="math/tex; mode=display">E(X) \approx \frac{1}{n}\sum\limits_{i = 1}^{n}x_i,where, X\sim p,x_i\sim p</script><p>But, there is a big assumption that we can efficiently draw samples from the true distribution $p$ of this random variable $X$. What if we can’t do that? Can we use some alternative distribution like $q$ and use the samples drawing from $q$ to correct the fact that we were drawing samples from the wrong distribution or get a better estimation than its true distribution $p$? There is where Importance sampling comes for.</p>
<a id="more"></a>
<p>In Importance Sampling, where $p$ is the true distribution of random variable $X$, and $q$ which is called <strong>proposal distribution</strong> that we use to sampling, and $q$ satisfied <strong>absolute continuity</strong> that $\forall q(pdfs), s.t. q(x) = 0 \rightarrow p(x) = 0$:</p>
<script type="math/tex; mode=display">
E_p[X] = \sum\limits_{x}xp(x) = \sum\limits_{x}x\frac{p(x)}{q(x)}q(x) = E_q[x\frac{p(x)}{q(x)}] \approx \frac{1}{n}\sum\limits_{i=1}^{n}x_i\frac{p(x_i)}{q(x_i)}, \quad where, x_i\sim q</script><p>Finally,  an unbiased estimator of the true expectation(Monte Carlo estimator is unbiased).</p>
<script type="math/tex; mode=display">
E_p[X] \approx \frac{1}{n}\sum\limits_{i=1}^{n}x_iw(x_i), \quad where, x_i\sim q, w(x_i) = \frac{p(x_i)}{q(x_i)}</script><p>$w(x)$ is called the <strong>importance weight</strong> , it will give more weight to the values that may appear more possible under its true distribution. And IS is worked no matter whether the $p$ is normalized, something like $p(x) = \frac{h(x)}{Z}$ or not.</p>
<script type="math/tex; mode=display">
E_p[X] = \sum\limits_{x}xp(x) = \sum\limits_{x}x\frac{h(x)}{Z} = \sum\limits_{x}x\frac{h(x)}{q(x)Z}q(x) \approx \frac{1}{Z}\frac{1}{n}\sum\limits_{i=1}^{n}x_i^q\frac{h(x_i^q)}{q(x_i^q)}</script><p>Now, $E_p[X=1] = 1 = \sum\limits_{x}\frac{h(x)}{Z}$, we can get:</p>
<script type="math/tex; mode=display">
Z =  \sum\limits_{x}h(x) = \sum\limits_{x}\frac{h(x)}{q(x)}q(x) \approx\frac{1}{n}\sum\limits_{i=1}^{n}\frac{h(x_i^q)}{q(x_i^q)} = \frac{1}{n}\sum\limits_{i=1}^{n}w(x_i^q) = \bar{w}</script><p>So, finally,</p>
<script type="math/tex; mode=display">
E_p[X] = \frac{\bar{xw}}{\bar{w}}</script><h4 id="2-A-bad-choice-of-q-makes-thing-worse"><a href="#2-A-bad-choice-of-q-makes-thing-worse" class="headerlink" title="2. A bad choice of $q$ makes thing worse."></a>2. A bad choice of $q$ makes thing worse.</h4><p><strong>Moral: Choose $q(x)$ large where $|x|p(x)$ large.</strong></p>
<p>Importance sampling is a <strong>variance reduction</strong> technique that can be used in the <strong>Monte Carlo method</strong>. The idea behind importance sampling is that <u><strong>certain values of the input random variables in a simulation have more impact on the parameter being estimated than others. If these “important” values are emphasized by sampling more frequently, then the estimator variance can be reduced</strong></u>. Hence, the basic methodology in importance sampling is <u><strong>to choose a distribution which “encourages” the important values</strong></u>. This use of “biased” distributions will result in a biased estimator if it is applied directly in the simulation. However, the simulation outputs are weighted to correct for the use of the biased distribution, and this ensures that the new importance sampling estimator is unbiased. The weight is given by the <strong>likelihood ratio</strong>, that is, the Radon–Nikodym derivative of the true underlying distribution with respect to the biased simulation distribution.(From Wikipedia)</p>
<p>The fundamental issue in implementing importance sampling simulation is the choice of the biased distribution which encourages the important regions of the input variables. Choosing or designing a good biased distribution is the “art” of importance sampling. The rewards for a good distribution can be <strong>huge run-time savings</strong>; the penalty for a bad distribution can be longer run times than for a general Monte Carlo simulation without importance sampling.(From Wikipedia)</p>
<p>Now, let $I = \frac{1}{n}\sum\limits_{i=1}^{n}x_iw(x_i)$, the variance of $I$, </p>
<script type="math/tex; mode=display">
\sigma^2(I) =  \frac{1}{n}\sigma^2(X\frac{p(X)}{q(X)})</script><p>a litte bit different from the standard Monte Carlo variance:</p>
<script type="math/tex; mode=display">
\sigma^2(I) =  \frac{1}{n}\sigma^2(X)</script><p>So this is how you can improve the expected error you can lower the expected error of your estimator by reducing this variance, because the mean square error is $mse = bias^2 + var$. It could be worse if you made a bad choice of $q$, a high variance made it hard to learn or converge. Also it could be much samller if you choose a good $q$. Often, people try to make $q$ as close to $p$ as possible.<br>For example:<br><img src="https://raw.githubusercontent.com/Huixxi/TensorFlow2.0-for-Deep-Reinforcement-Learning/master/images/rlblog_images/IS.jpg" alt><br>There are two proposal distributions $q$ and $T$ that we can use to estimate the expect value of $X$ which is under its true distribution $p$. If we choose to use $q$ distribution, we will get a high variance because under the $q$ distribution in most time the samples we get have a very small importance weights that don’t contribute to the estimator much, and occasionally it will get a very large importance weight when the sample appears in the middle part, and that makes it struggle to estimate from $q$ distribution. But for $T$, because in most time, we will get the samples from its middle part where have a relatively smooth importance weights that eventually get a much smaller variance than $q$, and that makes it converge much more quickly than $q$.</p>
<p>There is an optimal equation to choose the <strong>proposal distribution</strong> $q$:<br>Let $\mu = E_p[|X|] = $, if we choose a $q$ that: $q(x) = \frac{p(x)|x|}{\mu}$, we can get a zero-variance estimator.</p>
<h4 id="3-Applications"><a href="#3-Applications" class="headerlink" title="3. Applications"></a>3. Applications</h4><p>Such methods are frequently used to estimate posterior densities(后验密度估计) or expectations in state(状态期望值) and/or parameter estimation problems in probabilistic models(概率模型中的参数估计问题) that are too hard to treat analytically, for example in Bayesian networks.</p>
<h4 id="4-Conventional-biasing-methods"><a href="#4-Conventional-biasing-methods" class="headerlink" title="4. Conventional biasing methods"></a>4. Conventional biasing methods</h4><p><strong>Sacling:</strong><br>Shifting probability mass into the event region $X\geq t$ by positive scaling of the random variable $X$, with a number greater than unity has the effect of increasing the variance (mean also) of the density function. This results in a heavier tail of the density, leading to an increase in the event probability. However, while scaling shifts probability mass into the desired event region, it also pushes mass into the complementary region $X {&lt;} t $, which is undesirable. </p>
<script type="math/tex; mode=display">
f_{*}(x)={\frac  {1}{a}}f{\bigg (}{\frac  {x}{a}}{\bigg )}, w(x)=a{\frac  {f(x)}{f(x/a)}}</script><p><strong>Translation:</strong><br>Another simple and effective biasing technique employs translation of the density function (and hence random variable) to place much of its probability mass in the rare event region. Translation does not suffer from a dimensionality effect and has been successfully used in several applications relating to simulation of digital communication systems. It often provides better simulation gains than scaling. In biasing by translation, the simulation density is given by</p>
<script type="math/tex; mode=display">
f_{*}(x)=f(x-c),\quad c>0</script><p>where $c$  is the amount of shift and is to be chosen to minimize the variance of the importance sampling estimator.</p>
<h4 id="5-Evaluation-of-importance-sampling"><a href="#5-Evaluation-of-importance-sampling" class="headerlink" title="5. Evaluation of importance sampling"></a>5. Evaluation of importance sampling</h4><p>In order to identify successful importance sampling techniques, it is useful to be able to quantify the run-time savings due to the use of the importance sampling approach. The performance measure commonly used is $\sigma _{MC}^{2}/\sigma _{IS}^{2}$, and this can be interpreted as the speed-up factor by which the importance sampling estimator achieves the same precision as the MC estimator.</p>
<h4 id="6-Importance-Sampling-in-Deep-Reinforcement-Learning"><a href="#6-Importance-Sampling-in-Deep-Reinforcement-Learning" class="headerlink" title="6. Importance Sampling in Deep Reinforcement Learning"></a>6. Importance Sampling in Deep Reinforcement Learning</h4><p>We often see this term in reinforcement learning paper, like the “Prioritized experience replay”, “PPO”,etc. And now, we’re going to explore why they use IS, and how they use it.</p>
<p><strong>Prioritized Experience Replay</strong><br>The importance weight here is:</p>
<script type="math/tex; mode=display">
w_i={\bigg (}{\frac {1}{N}\frac {1}{P(i)} }{\bigg )}^{\beta} / max_i w_i</script><p>There are two excellent explanation about the Importace Sampling Correction appears in PER:</p>
<ul>
<li><a href="https://datascience.stackexchange.com/questions/32873/prioritized-replay-what-does-importance-sampling-really-do" target="_blank" rel="noopener">Prioritized Replay, what does Importance Sampling really do?</a></li>
<li><a href="https://danieltakeshi.github.io/2019/07/14/per/" target="_blank" rel="noopener">Understanding Prioritized Experience Replay</a></li>
</ul>
<p><strong>TL;DR</strong>  the importance sampling in PER is to correct the over-sampling with respect to the uniform distribution.</p>
<p>In paper Prioritized Experience Replay, it said: “In particular, we propose to more frequently replay transitions with high expected learning progress, as measured by the magnitude of their temporal-difference (TD) error. This prioritization can lead to a loss of diversity, which we alleviate with stochastic prioritization, and introduce bias, which we correct with importance sampling. “</p>
<p>And DeepMind describes why we need an Importace Sampling Correction:</p>
<blockquote>
<p>The estimation of the expected value with stochastic updates relies on those updates corresponding to the same distribution as its expectation. Prioritized replay introduces bias because it changes this distribution in an uncontrolled fashion, and therefore changes the solution that the estimates will converge to (even if the policy and state distribution are fixed). We can correct this bias by using importance-sampling (IS) weights.</p>
</blockquote>
<p>Now the loss we want to minimize in DQN is: </p>
<script type="math/tex; mode=display">L_i(\theta_i) = E_{(s, a, r, s') \sim U(D)}[(r + \lambda max_{a'}Q(s', a';\theta_i^{-}) - Q(s_i, a_i;\theta_i))^2]</script><p>Let $X = (r + \lambda max_{a’}Q(s’, a’;\theta_i^{-}) - Q(s_i, a_i;\theta_i))^2$ which should under its “true” distribution $U(D)$ - the Uniform Distribution($1/N$),  but now the samples $X$ we get are under the stochastic prioritization distribution $P$, so we need the Importance Sampling Correction to down-weight those samples with high prority which has a higher $P(i)$ to be choose to eliminate the bias it brings. Incidentally, the $\beta$ here is a kind of bias-variance trade-off method, as $\beta$ grows from $\beta_0$ to $1$, the bias is gradually eliminated, which means IS is more important near convergence.</p>
<p><strong><a href="https://www.quora.com/Why-doesn-t-DQN-use-importance-sampling-Dont-we-always-use-this-method-to-correct-the-sampling-error-produced-by-the-off-policy/answer/James-MacGlashan" target="_blank" rel="noopener">But why we don’t use Importance sampling in DQN?</a></strong><br>The important property here is the sampling Q-learning does is over the <strong>probability distribution of the environment state transitions</strong>, not over the <strong>policy distribution</strong>. Consequently, we don’t need to correct for different policy distributions!</p>
<h3 id="REFERENCES"><a href="#REFERENCES" class="headerlink" title="REFERENCES"></a><u>REFERENCES</u></h3><p><strong>Wikipedia:</strong> </p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Importance_sampling" target="_blank" rel="noopener">Importance Sampling</a></li>
</ul>
<p><strong>Videos:</strong> </p>
<ul>
<li><a href="https://www.youtube.com/watch?v=V8f8ueBc9sY" target="_blank" rel="noopener">An introduction to importance sampling</a></li>
<li><a href="https://www.youtube.com/watch?v=F5PdIQxMA28" target="_blank" rel="noopener">An introduction to importance sampling - optimal importance distributions</a></li>
<li><a href="https://www.youtube.com/watch?v=S3LAOZxGcnk" target="_blank" rel="noopener">(ML 17.5) Importance sampling - introduction</a></li>
<li><a href="https://www.youtube.com/watch?v=3Mw6ivkDVZc" target="_blank" rel="noopener">(ML 17.6) Importance sampling - intuition</a></li>
<li><a href="https://www.youtube.com/watch?v=gYvlnu5AAzE" target="_blank" rel="noopener">(ML 17.7) Importance sampling without normalization constants</a></li>
</ul>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Reinforcement-Learning/" rel="tag">#Reinforcement Learning</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/05/26/RL-OpenAI-Gym-Tutorial/" rel="next" title="RL_OpenAI_Gym_Tutorial">
                <i class="fa fa-chevron-left"></i> RL_OpenAI_Gym_Tutorial
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/06/02/小白视角：一文读懂社长的TinyWebServer/" rel="prev" title="小白视角：一文读懂社长的TinyWebServer">
                小白视角：一文读懂社长的TinyWebServer <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/Elon-Musk.jpg" alt="Hugo">
          <p class="site-author-name" itemprop="name">Hugo</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">22</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">6</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/Huixxi" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.linkedin.com/in/uestc-hugo/" target="_blank" title="LinkedIn">
                  
                    <i class="fa fa-fw fa-linkedin"></i>
                  
                  LinkedIn
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/______HU______" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://stackoverflow.com/users/7121726/hu-xixi" target="_blank" title="Stackoverflow">
                  
                    <i class="fa fa-fw fa-stack-overflow"></i>
                  
                  Stackoverflow
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Importance-Sampling"><span class="nav-number">1.</span> <span class="nav-text">Importance Sampling</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-What-is-Importance-Sampling"><span class="nav-number">1.0.1.</span> <span class="nav-text">1.What is Importance Sampling</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-A-bad-choice-of-q-makes-thing-worse"><span class="nav-number">1.0.2.</span> <span class="nav-text">2. A bad choice of $q$ makes thing worse.</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-Applications"><span class="nav-number">1.0.3.</span> <span class="nav-text">3. Applications</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-Conventional-biasing-methods"><span class="nav-number">1.0.4.</span> <span class="nav-text">4. Conventional biasing methods</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-Evaluation-of-importance-sampling"><span class="nav-number">1.0.5.</span> <span class="nav-text">5. Evaluation of importance sampling</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-Importance-Sampling-in-Deep-Reinforcement-Learning"><span class="nav-number">1.0.6.</span> <span class="nav-text">6. Importance Sampling in Deep Reinforcement Learning</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#REFERENCES"><span class="nav-number">1.1.</span> <span class="nav-text">REFERENCES</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hugo</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/VEN/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/VEN/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/VEN/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/VEN/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/VEN/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/VEN/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.2"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.2"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'hugo-818';
      var disqus_identifier = '2020/05/26/RL-Importance-Sampling/';
      var disqus_title = "RL_Importance_Sampling";
      var disqus_url = 'http://huixxi.github.io/2020/05/26/RL-Importance-Sampling/';

      function run_disqus_script(disqus_script){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');
      
        run_disqus_script('embed.js');
      
    </script>
  




  
  

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  

</body>
</html>
