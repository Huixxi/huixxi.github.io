<!doctype html>



  


<html class="theme-next pisces use-motion">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">












  
  
  <link href="/VEN/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/VEN/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.0.2" rel="stylesheet" type="text/css">


  <meta name="keywords" content="Hexo, NexT">








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.2">






<meta property="og:type" content="website">
<meta property="og:title" content="HU">
<meta property="og:url" content="http://huixxi.github.io/index.html">
<meta property="og:site_name" content="HU">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HU">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    }
  };
</script>




  <link rel="canonical" href="http://huixxi.github.io/">


  <title> HU </title>
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">HU</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">\&</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2062/01/31/Navigation/" itemprop="url">
                  Navigation
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2062-01-31T13:29:39+08:00" content="2062-01-31">
              2062-01-31
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2062/01/31/Navigation/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2062/01/31/Navigation/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p align="center">ORDINARY PEOPLE COULD CHOOSE TO BE EXTRAORDINARY.</p>


<h2 id="Github-Repos"><a href="#Github-Repos" class="headerlink" title="Github Repos"></a>Github Repos</h2><ul>
<li><a href="https://github.com/Huixxi/TensorFlow2.0-for-Deep-Reinforcement-Learning" target="_blank" rel="noopener">TensorFlow 2.0 for Deep Reinforcement Learning</a></li>
<li><a href="https://github.com/Huixxi/CS234-Reinforcement-Learning" target="_blank" rel="noopener">CS234:Reinforcement Learning</a></li>
<li><a href="https://github.com/Huixxi/NLP_Word2Vec" target="_blank" rel="noopener">Word2Vec:Skip-Gram Model</a></li>
<li><a href="https://github.com/Huixxi/Fast-Py3" target="_blank" rel="noopener">Fast-Py3: A Fast Python3 tutoial For Beginners</a></li>
<li><a href="https://github.com/Huixxi/Image-Classification-using-Flowers-dataset" target="_blank" rel="noopener">Image Classification using Flowers-dataset</a></li>
</ul>
<h2 id="Paper-Overview"><a href="#Paper-Overview" class="headerlink" title="Paper Overview"></a>Paper Overview</h2><ul>
<li><a href="https://huixxi.github.io/2019/05/12/RL-Paper-01/">RL_Paper_01 — Self-Regulated Learning - 2018</a></li>
<li><a href="https://huixxi.github.io/2019/05/12/RL-Paper-01/">RL_Paper_02 — Deep Q-Network - 2015</a></li>
<li><a href="https://huixxi.github.io/2019/05/12/RL-Paper-01/">RL_Paper_03 — Rainbow - 2017</a></li>
</ul>
<h2 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h2><ul>
<li><a href="https://huixxi.github.io/2017/06/09/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E6%90%AD%E5%BB%BATensorFlow%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/#more">Linux服务器上搭建TensorFlow机器学习环境</a></li>
<li><a href="https://huixxi.github.io/2017/12/05/Markdown-Syntax/#more">Markdown Syntax</a></li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/12/15/Pek-Auto/" itemprop="url">
                  Pek_Auto
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2019-12-15T19:02:14+08:00" content="2019-12-15">
              2019-12-15
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2019/12/15/Pek-Auto/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/12/15/Pek-Auto/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="My-First-Kaggle-Competition"><a href="#My-First-Kaggle-Competition" class="headerlink" title="My First Kaggle Competition"></a>My First Kaggle Competition</h1><p><a href="https://www.kaggle.com/c/pku-autonomous-driving/overview" target="_blank" rel="noopener">Peking University/Baidu - Autonomous Driving</a></p>
<ul>
<li>Baseline: <a href="https://www.kaggle.com/phoenix9032/center-resnet-starter" target="_blank" rel="noopener">CenterResnet Starter</a><br>第一次接触这个比赛，啥也不会，直接参考（复制）了一位大佬公布的Kernel，直接可以跑通，学习了。整理了一下代码，最终使用ResNet34(Pre-trained)作为Baseline。</li>
<li></li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/12/03/CV-HumanActionRec/" itemprop="url">
                  CV-HumanActionRec
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2019-12-03T14:37:00+08:00" content="2019-12-03">
              2019-12-03
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2019/12/03/CV-HumanActionRec/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/12/03/CV-HumanActionRec/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="公开数据集"><a href="#公开数据集" class="headerlink" title="公开数据集"></a>公开数据集</h2><ul>
<li><a href="https://deepmind.com/research/open-source/kinetics" target="_blank" rel="noopener">Kinetics-400/600/700</a></li>
<li><a href="https://www.crcv.ucf.edu/data/UCF101.php" target="_blank" rel="noopener">UCF-101/50/11</a></li>
<li><a href="http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#dataset" target="_blank" rel="noopener">HMDB-51</a></li>
</ul>
<h2 id="视频行为识别流程"><a href="#视频行为识别流程" class="headerlink" title="视频行为识别流程"></a>视频行为识别流程</h2><h2 id="“Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos“"><a href="#“Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos“" class="headerlink" title="“Two-Stream Convolutional Networks for Action Recognition in Videos“"></a>“Two-Stream Convolutional Networks for Action Recognition in Videos“</h2><p><code>&gt;</code><a href="https://papers.nips.cc/paper/5353-two-stream-convolutional-networks-for-action-recognition-in-videos.pdf" target="_blank" rel="noopener">[Paper]</a>[[Code]]<br><code>Conference: NIPS</code><br><code>Year: 2014</code><br><code>Institute: Oxford</code><br><code>Author: Karen Simonyan, Andrew Zisserman</code><br><code>#</code><br>利用双路卷积神经网络，空域流处理图片，在每个视频样本中随机抽取一帧；时域流处理光流信息，对于空域中的每一帧图片，生成相应图片的光流信息，stack of flow， x和y方向级联成2L通道数的光流块；</p>
<p><strong>处理的问题</strong></p>
<ul>
<li>处理光流信息中的相机抖动问题</li>
</ul>
<h2 id="”3D-Convolutional-Neural-Networks-for-Human-Action-Recognition”"><a href="#”3D-Convolutional-Neural-Networks-for-Human-Action-Recognition”" class="headerlink" title="”3D Convolutional Neural Networks for Human Action Recognition”"></a>”3D Convolutional Neural Networks for Human Action Recognition”</h2><p><code>&gt;</code><a href="https://www.dbs.ifi.lmu.de/~yu_k/icml2010_3dcnn.pdf" target="_blank" rel="noopener">[Paper]</a>[[Code]]  </p>
<p>使用三维的卷积核，考虑时间维度的信息。</p>
<h2 id="“Learning-Spatiotemporal-Features-with-3D-Convolutional-Networks-C3D-”"><a href="#“Learning-Spatiotemporal-Features-with-3D-Convolutional-Networks-C3D-”" class="headerlink" title="“Learning Spatiotemporal Features with 3D Convolutional Networks(C3D)”"></a>“Learning Spatiotemporal Features with 3D Convolutional Networks(C3D)”</h2><p><code>&gt;</code><a href="https://arxiv.org/pdf/1412.0767.pdf" target="_blank" rel="noopener">[Paper]</a>[[Code]]<br><code>Conference:</code><br><code>Year: 2015</code><br><code>Institute: FaceBook</code><br><code>Author: Du Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani, Manohar Paluri</code><br><code>#</code>  </p>
<h2 id="“Quo-Vadis-Action-Recognition-A-New-Model-and-the-Kinetics-Dataset-I3D-”"><a href="#“Quo-Vadis-Action-Recognition-A-New-Model-and-the-Kinetics-Dataset-I3D-”" class="headerlink" title="“Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset(I3D)”"></a>“Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset(I3D)”</h2><p><code>&gt;</code><a href="https://arxiv.org/pdf/1705.07750.pdf" target="_blank" rel="noopener">[Paper]</a>[[Code]]<br><code>Conference: CVPR</code><br><code>Year: 2018</code><br><code>Institute: DeepMind</code><br><code>Author: Joao Carreira, Andrew Zisserman</code><br><code>#</code>  </p>
<h2 id="“Learning-Spatio-Temporal-Features-with-3D-Residual-Networks-for-Action-Recognition”"><a href="#“Learning-Spatio-Temporal-Features-with-3D-Residual-Networks-for-Action-Recognition”" class="headerlink" title="“Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition”"></a>“Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition”</h2><p><code>&gt;</code><a href="http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w44/Hara_Learning_Spatio-Temporal_Features_ICCV_2017_paper.pdf" target="_blank" rel="noopener">[Paper]</a>[[Code]]<br><code>Conference: ICCV</code><br><code>Year: 2017</code><br><code>Institute: AIST</code><br><code>Author: JKensho Hara, Hirokatsu Kataoka, Yutaka Satoh</code><br><code>#</code>  </p>
<h2 id="“SlowFast-Networks-for-Video-Recognition”"><a href="#“SlowFast-Networks-for-Video-Recognition”" class="headerlink" title="“SlowFast Networks for Video Recognition”"></a>“SlowFast Networks for Video Recognition”</h2><p><code>&gt;</code><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Feichtenhofer_SlowFast_Networks_for_Video_Recognition_ICCV_2019_paper.pdf" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/facebookresearch/SlowFast" target="_blank" rel="noopener">[Code]</a><br><code>Conference: ICCV</code><br><code>Year: 2019</code><br><code>Institute: FaceBook</code><br><code>Author: Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, Kaiming He</code><br><code>#</code>  </p>
<p>提出一种非利用光流信息的双路神经网络结构，用于处理慢速帧和快速帧的视频。</p>
<ul>
<li>Slow Pathway<br>用于处理慢速帧，提取空域中的静态语义信息。使用<strong>3D ResNet</strong>提取图像中的语义信息，不采用<strong>temporal downsampling</strong>，采用不同于<strong>C3D/I3D</strong>的<strong>非退化时间卷积（non-degenerate）</strong>。</li>
<li>Fast Pathway<br>用于处理快速帧，提取时域中快速变化的运动信息。采用轻量级网络，降低通道容量，仅关注时域信息。</li>
<li>Lateral Connections<br>Slow和Fast处理的是同一段视频的不同采样频率的视频片段。横向连接将双路特征进行融合。</li>
</ul>
<p><strong>处理的问题</strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/11/18/CV-Struct2Depth/" itemprop="url">
                  CV_Struct2Depth
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2019-11-18T20:04:50+08:00" content="2019-11-18">
              2019-11-18
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2019/11/18/CV-Struct2Depth/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/11/18/CV-Struct2Depth/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Learning-Google’s-Struct2Depth-from-Scratch"><a href="#Learning-Google’s-Struct2Depth-from-Scratch" class="headerlink" title="Learning Google’s Struct2Depth from Scratch."></a>Learning Google’s Struct2Depth from Scratch.</h1><p><strong>(An Unsupervised Monocular Depth Estimation Model)</strong><br><a href="https://arxiv.org/pdf/1811.06152.pdf" target="_blank" rel="noopener">[Paper]</a><a href="https://github.com/tensorflow/models/tree/master/research/struct2depth" target="_blank" rel="noopener">[Source code]</a>  </p>
<p><strong>Contributions:</strong></p>
<ul>
<li>Modeling dynamic scenes by modeling object motion.</li>
<li>Adapt its learning strategy with an online refinement technique.  </li>
</ul>
<p><img src="./struct2depth.png" alt="la"></p>
<p><strong>Code Structure:</strong></p>
<ul>
<li><code>alignment.py</code></li>
<li><code>gen_data_city.py</code></li>
<li><code>gen_data_kitti.py</code></li>
<li><code>inference.py</code></li>
<li><code>model.py</code></li>
<li><code>nets.py</code></li>
<li><code>optimize.py</code></li>
<li><code>project.py</code></li>
<li><code>reader.py</code></li>
<li><code>train.py</code></li>
<li><code>util.py</code></li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/10/23/CV-Depth-Estimation/" itemprop="url">
                  CV_Depth-Estimation
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2019-10-23T09:40:05+08:00" content="2019-10-23">
              2019-10-23
            </time>
          </span>

          
            <span class="post-category">
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Paper/" itemprop="url" rel="index">
                    <span itemprop="name">Paper</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2019/10/23/CV-Depth-Estimation/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/10/23/CV-Depth-Estimation/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="深度感知"><a href="#深度感知" class="headerlink" title="深度感知"></a>深度感知</h2><p>1.双眼视角 2.先验知识 3.光线阴影</p>
<h2 id="Available-Datasets"><a href="#Available-Datasets" class="headerlink" title="Available Datasets:"></a>Available Datasets:</h2><ul>
<li><a href="http://www.cvlibs.net/datasets/kitti/eval_depth_all.php" target="_blank" rel="noopener">KITTI</a></li>
<li><a href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" target="_blank" rel="noopener">NYU-V2</a></li>
<li><a href="http://make3d.cs.cornell.edu/data.html" target="_blank" rel="noopener">Make3D</a></li>
</ul>
<h2 id="Loss-Functions"><a href="#Loss-Functions" class="headerlink" title="Loss Functions"></a>Loss Functions</h2><p>SSIM<br>For self-supervised learning:</p>
<script type="math/tex; mode=display">
L_p(I_t, \hat{I}_t) = \alpha_1 \frac{1-SSIM(I_t, \hat{I}_t)}{2} + (1-\alpha_1)||I_t- \hat{I}_t||</script><h2 id="Network-Architectures"><a href="#Network-Architectures" class="headerlink" title="Network Architectures"></a>Network Architectures</h2><p>Autoencoder Structure with Skip Connections.</p>
<h2 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h2><h2 id="Application-Scenarios"><a href="#Application-Scenarios" class="headerlink" title="Application Scenarios"></a>Application Scenarios</h2><h2 id="Innovation-Points"><a href="#Innovation-Points" class="headerlink" title="Innovation Points"></a>Innovation Points</h2><ul>
<li>Semi/Un/Self Supervised Learning</li>
<li>Attention Mechanism</li>
<li>More Useful Loss Function</li>
<li>More Efficient Network</li>
<li>Reinforcement Learning</li>
<li>Knowledge Distill</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><ul>
<li>Structure from motion(SfM)</li>
<li>Learning single-view 3D from registered 2D views</li>
<li>Warping-based view synthesis</li>
<li>Unsupervised/Self-supervised learning from video</li>
</ul>
<hr>
<hr>
<h2 id="SuperDepth-Self-Supervised-Super-Resolved-Monocular-Depth-Estimation"><a href="#SuperDepth-Self-Supervised-Super-Resolved-Monocular-Depth-Estimation" class="headerlink" title="SuperDepth: Self-Supervised, Super-Resolved Monocular Depth Estimation"></a>SuperDepth: Self-Supervised, Super-Resolved Monocular Depth Estimation</h2><p><code>&gt;</code><a href="https://arxiv.org/pdf/1810.01849.pdf" target="_blank" rel="noopener">[Paper]</a> [[Code]]<br><code>Conference: CVPR</code><br><code>Year: 2018</code><br><code>Institute: TRI</code><br><code>Author: Sudeep Pillai, Rares, Ambrus, Adrien Gaidon</code><br><code>#</code><em>Self-supervised Learning</em>, <em>Monocular</em>, <em>Stereo Imagery</em></p>
<p><strong>What they did:</strong></p>
<ul>
<li>Proposed a sub-pixel convolutional layer extension for depth super-resolution.</li>
<li>Introduce a differentiable flip-augmentation layer</li>
</ul>
<p><strong>Why they did:</strong><br>To solve: high resolution monocular depth prediction.</p>
<p><strong>Innovation points:</strong></p>
<ul>
<li></li>
<li></li>
</ul>
<h2 id="Depth-Prediction-Without-the-Sensors-Leveraging-Structure-for-Unsupervised-Learning-from-Monocular-Videos"><a href="#Depth-Prediction-Without-the-Sensors-Leveraging-Structure-for-Unsupervised-Learning-from-Monocular-Videos" class="headerlink" title="Depth Prediction Without the Sensors: Leveraging Structure for Unsupervised Learning from Monocular Videos"></a>Depth Prediction Without the Sensors: Leveraging Structure for Unsupervised Learning from Monocular Videos</h2><p><code>&gt;</code><a href="https://arxiv.org/pdf/1811.06152.pdf" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/tensorflow/models/tree/master/research/struct2depth" target="_blank" rel="noopener">[Code]</a><br><code>Conference: CVPR</code><br><code>Year: 2018</code><br><code>Institute: Google Brain</code><br><code>Author: Reza Mahjourian, Martin Wicke, Anelia Angelova</code><br><code>#</code><em>Unsupervised Learning</em>, <em>Monocular Video</em></p>
<p><strong>What they did:</strong></p>
<ul>
<li>Proposed a novel unsupervised algorithm for depth and ego-motion from monocular video.</li>
<li>Take the 3D structure of the world into consideration by a 3D loss function.</li>
</ul>
<p><strong>Why they did:</strong><br>To solve: </p>
<p><strong>Innovation points:</strong></p>
<ul>
<li></li>
<li></li>
</ul>
<h2 id="Unsupervised-Learning-of-Depth-and-Ego-Motion-from-Monocular-Video-Using-3D-Geometric-Constraints"><a href="#Unsupervised-Learning-of-Depth-and-Ego-Motion-from-Monocular-Video-Using-3D-Geometric-Constraints" class="headerlink" title="Unsupervised Learning of Depth and Ego-Motion from Monocular Video Using 3D Geometric Constraints"></a>Unsupervised Learning of Depth and Ego-Motion from Monocular Video Using 3D Geometric Constraints</h2><p><code>&gt;</code><a href="https://arxiv.org/pdf/1802.05522v2.pdf" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/tensorflow/models/tree/master/research/vid2depth" target="_blank" rel="noopener">[Code]</a><br><code>Conference: CVPR</code><br><code>Year: 2018</code><br><code>Institute: Google Brain</code><br><code>Author: Reza Mahjourian, Martin Wicke, Anelia Angelova</code><br><code>#</code><em>Unsupervised Learning</em>, <em>Monocular Video</em></p>
<p><strong>What they did:</strong></p>
<ul>
<li>Proposed a novel unsupervised algorithm for depth and ego-motion from monocular video.</li>
<li>Take the 3D structure of the world into consideration by a 3D loss function.</li>
</ul>
<p><strong>Why they did:</strong><br>To solve: </p>
<p><strong>Innovation points:</strong></p>
<ul>
<li></li>
<li></li>
</ul>
<h2 id="Single-Image-Depth-Estimation-Trained-via-Depth-from-Defocus-Cues"><a href="#Single-Image-Depth-Estimation-Trained-via-Depth-from-Defocus-Cues" class="headerlink" title="Single Image Depth Estimation Trained via Depth from Defocus Cues"></a>Single Image Depth Estimation Trained via Depth from Defocus Cues</h2><p><code>&gt;</code><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Gur_Single_Image_Depth_Estimation_Trained_via_Depth_From_Defocus_Cues_CVPR_2019_paper.pdf" target="_blank" rel="noopener">[Paper]</a> [[Code]]<br><code>Conference: CVPR</code><br><code>Year: 2019</code><br><code>Institute: Facebook AI</code><br><code>Author: Shir Gur, Lior Wolf</code><br><code>#</code><em>Unsupervised Learning</em>, <em>Defocus Cues</em></p>
<p><strong>Terms:</strong></p>
<ul>
<li><p><strong>Structure from motion(SfM)</strong> 运动中结构重建<br>Estimating three-dimensional structures from two-dimensional image sequences that may be coupled with local motion signals.<br>利用可能与局部运动信号耦合的二维图像序列估计三维结构</p>
</li>
<li><p><strong>Point spread function(PSF)</strong>点扩散函数<br>Describes the response of an imaging system to a point source or point object.<br>用于描述一个图像系统对一个点源或是点目标的响应。</p>
</li>
</ul>
<p><strong>What they did:</strong></p>
<ul>
<li>Rely, instead of multiple view geometry, on shape from defocus. </li>
<li>Proposed a novel Point Spread Function(PSF) layer, combining the successful <strong>ASPP</strong> architecture</li>
<li>Dense connections and self-attention</li>
</ul>
<p>$I$ — all-in-focus image; $D_o$ — depth-map; $\rho$ — camera parameters vector(the aperture $A$, the focal length $F$ and the focal depth $D_f$);<br>There are two network: $f$ for depth estimation and $g$ for focus rendering, and $f$ is learned.<br>The learned network $f$ takes $I$ as input, and output a predicted depth $\bar{D}_o$. Then input $I$, $\bar{D}_o$, $\rho$ to $g$, and output a estimated rendered focused image $\bar{J}$.<br>The fixed network $g$ consists of the PSF layer takes $I$, $D_o$, $\rho$ as input, and output a rendered focus image $J$.</p>
<ul>
<li>Atrous Convlution</li>
<li>Atrous Spatial Pyramid Pooling(ASPP)</li>
</ul>
<p><strong>Why they did:</strong><br>To solve: </p>
<p><strong>Innovation points:</strong></p>
<ul>
<li></li>
<li></li>
</ul>
<h2 id="Digging-Into-Self-Supervised-Monocular-Depth-Estimation"><a href="#Digging-Into-Self-Supervised-Monocular-Depth-Estimation" class="headerlink" title="Digging Into Self-Supervised Monocular Depth Estimation"></a>Digging Into Self-Supervised Monocular Depth Estimation</h2><p><code>&gt;</code><a href="https://arxiv.org/pdf/1806.01260v4.pdf" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/nianticlabs/monodepth2" target="_blank" rel="noopener">[Code]</a><br><code>Conference: ICCV</code><br><code>Year: 2019</code><br><code>Institute:</code><br><code>Author: Cl´ement Godard, Oisin Mac Aodha, Michael Firman, Gabriel Brostow</code><br><code>#</code><em>self-supervised Learning</em>, <em>Monocular</em>    </p>
<p><strong>What they did:</strong></p>
<ul>
<li>A minimum reprojection loss, designed to robustly handle occlusions.</li>
<li>A full-resolution multi-scale sampling method that reduces visual artifacts.</li>
<li>An auto-masking loss to ignore training pixels that violate camera motion assumptions.</li>
</ul>
<h2 id="Learning-Depth-from-Monocular-Videos-using-Direct-Methods"><a href="#Learning-Depth-from-Monocular-Videos-using-Direct-Methods" class="headerlink" title="Learning Depth from Monocular Videos using Direct Methods"></a>Learning Depth from Monocular Videos using Direct Methods</h2><p><code>&gt;</code><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Learning_Depth_From_CVPR_2018_paper.pdf" target="_blank" rel="noopener">[Paper]</a> [[Code]]<br><code>Conference: CVPR</code><br><code>Year: 2017</code><br><code>Institute:</code><br><code>Author: Chaoyang Wang, Jos´e Miguel Buenaposada, Rui Zhu, Simon Lucey</code><br><code>#</code><em>unsupervised Learning</em>, <em>monocular</em></p>
<p><strong>What they did:</strong></p>
<ul>
<li>Explain why scale ambiguity in current monocular methods is problematic</li>
<li>Propose a simple normalization strategy</li>
<li>Incorporation of a Direct Visual Odometry (DVO) pose predictor</li>
<li>Considered the geometric relation between camera pose and depth</li>
</ul>
<h2 id="Unsupervised-Learning-of-Depth-and-Ego-Motion-from-Video"><a href="#Unsupervised-Learning-of-Depth-and-Ego-Motion-from-Video" class="headerlink" title="Unsupervised Learning of Depth and Ego-Motion from Video"></a>Unsupervised Learning of Depth and Ego-Motion from Video</h2><p><code>&gt;</code><a href="https://people.eecs.berkeley.edu/~tinghuiz/projects/SfMLearner/cvpr17_sfm_final.pdf" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/tinghuiz/SfMLearner" target="_blank" rel="noopener">[Code]</a><br><code>Conference: CVPR</code><br><code>Year: 2017</code><br><code>Institute:</code><br><code>Author: Tinghui Zhou, Matthew Brown, Noah Snavely, David G. Lowe</code><br><code>#</code><em>unsupervised Learning</em>, <em>monocular</em></p>
<p><strong>What they did:</strong></p>
<ul>
<li>Using single-view depth and multi-view pose networks, with a loss based on warping nearby views to the target using the computed depth and pose. </li>
<li>Explainability mask discounts</li>
<li>Overcoming the gradient locality by using a convolutional encoder-decoder architec- ture with a small bottleneck</li>
</ul>
<h2 id="Unsupervised-Monocular-Depth-Estimation-with-Left-Right-Consistency"><a href="#Unsupervised-Monocular-Depth-Estimation-with-Left-Right-Consistency" class="headerlink" title="Unsupervised Monocular Depth Estimation with Left-Right Consistency"></a>Unsupervised Monocular Depth Estimation with Left-Right Consistency</h2><p><code>&gt;</code><a href="https://arxiv.org/pdf/1609.03677.pdf" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/mrharicot/monodepth" target="_blank" rel="noopener">[Code]</a><br><code>Conference: CVPR</code><br><code>Year: 2017</code><br><code>Institute:</code><br><code>Author: Cl´ement Godard, Oisin Mac Aodha, Gabriel J. Brostow</code><br><code>#</code><em>unsupervised Learning</em>, <em>binocular stereo footage</em></p>
<p><strong>What they did:</strong></p>
<ul>
<li>Introduce a novel depth estimation training loss </li>
<li>Featuring an inbuilt left-right consistency check</li>
<li></li>
</ul>
<h2 id="Real-Time-Monocular-Depth-Estimation-using-Synthetic-Data-with-Domain-Adaptation-via-Image-Style-Transfer"><a href="#Real-Time-Monocular-Depth-Estimation-using-Synthetic-Data-with-Domain-Adaptation-via-Image-Style-Transfer" class="headerlink" title="Real-Time Monocular Depth Estimation using Synthetic Data with Domain Adaptation via Image Style Transfer"></a>Real-Time Monocular Depth Estimation using Synthetic Data with Domain Adaptation via Image Style Transfer</h2><p><code>&gt;</code><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Atapour-Abarghouei_Real-Time_Monocular_Depth_CVPR_2018_paper.pdf" target="_blank" rel="noopener">[Paper]</a> [[Code]]<br><code>Conference: CVPR</code><br><code>Year: 2018</code><br><code>Institute:</code><br><code>Author: Amir Atapour-Abarghouei, Toby P. Breckon</code><br><code>#</code><em>supervised Learning</em>, <em>monocular</em>, <em>image style transfer</em>, <em>domain adaptation</em></p>
<p><strong>What they did:</strong></p>
<ul>
<li>Synthetic depth prediction - apredict depth based on high quality synthetic depth training data(supervise learning)</li>
<li>Domain adaptation via style transfer</li>
<li></li>
</ul>
<h2 id="Depth-map-prediction-from-a-single-image-using-a-multi-scale-deep-network"><a href="#Depth-map-prediction-from-a-single-image-using-a-multi-scale-deep-network" class="headerlink" title="Depth map prediction from a single image using a multi-scale deep network."></a>Depth map prediction from a single image using a multi-scale deep network.</h2><p><code>&gt;</code><a href="http://papers.nips.cc/paper/5539-depth-map-prediction-from-a-single-image-using-a-multi-scale-deep-network.pdf" target="_blank" rel="noopener">[Paper]</a><br> <code>Conference: NIPS</code><br><code>Year: 2014</code><br><code>Institute:</code><br><code>Author: David Eigen, Christian Puhrsch, Rob Fergus</code><br><code>#</code><em>supervised Learning</em></p>
<p><strong>What they did:</strong></p>
<ul>
<li>Using a scale-invariant error in addition to more common scale-dependent errors</li>
<li>One that first estimates the global structure of the scene, then a second that refines it using local information</li>
</ul>
<p><strong>Why they did:</strong><br>To solve: the global scale</p>
<p><strong>Innovation points:</strong></p>
<ul>
<li>Collecting dataset(indoor&amp;outdoor) from websites, social media outlets, real estate listings, and shopping sites.</li>
</ul>
<h2 id="Deeper-Depth-Prediction-with-Fully-Convolutional-Residual-Networks"><a href="#Deeper-Depth-Prediction-with-Fully-Convolutional-Residual-Networks" class="headerlink" title="Deeper Depth Prediction with Fully Convolutional Residual Networks"></a>Deeper Depth Prediction with Fully Convolutional Residual Networks</h2><p><code>&gt;</code><a href="https://arxiv.org/pdf/1606.00373v2.pdf" target="_blank" rel="noopener">[Paper]</a> <a href="https://github.com/iro-cp/FCRN-DepthPrediction" target="_blank" rel="noopener">[Code]</a><br><code>Conference:</code><br><code>Year: 2016</code><br><code>Institute:</code><br><code>Author: Iro Laina, Christian Rupprecht, Vasileios Belagiannis, Federico Tombari, Nassir Navab</code><br><code>#</code><em>supervised Learning</em></p>
<p><strong>What they did:</strong></p>
<ul>
<li>A fully convolutional architecture, encompassing residual learning.</li>
<li>Efficiently learn feature map up-sampling within the network, up-projection layer.</li>
<li>Reverse Huber loss.</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/07/04/RL-Self-Learning/" itemprop="url">
                  RL_Self-Learning
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2019-07-04T18:24:33+08:00" content="2019-07-04">
              2019-07-04
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2019/07/04/RL-Self-Learning/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/07/04/RL-Self-Learning/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/07/04/RL-Attention/" itemprop="url">
                  RL_Attention
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2019-07-04T18:24:04+08:00" content="2019-07-04">
              2019-07-04
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2019/07/04/RL-Attention/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/07/04/RL-Attention/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/07/04/RL-LSTM/" itemprop="url">
                  RL_LSTM
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2019-07-04T18:23:54+08:00" content="2019-07-04">
              2019-07-04
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2019/07/04/RL-LSTM/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/07/04/RL-LSTM/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/07/04/RL-OpenAI-Five/" itemprop="url">
                  RL_OpenAI_Five
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2019-07-04T16:47:53+08:00" content="2019-07-04">
              2019-07-04
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2019/07/04/RL-OpenAI-Five/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/07/04/RL-OpenAI-Five/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/07/04/RL-Paper-05_Hierarchical RL/" itemprop="url">
                  RL_Paper_05:Hierarchical RL
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2019-07-04T16:10:09+08:00" content="2019-07-04">
              2019-07-04
            </time>
          </span>

          
            <span class="post-category">
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Paper/" itemprop="url" rel="index">
                    <span itemprop="name">Paper</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2019/07/04/RL-Paper-05_Hierarchical RL/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/07/04/RL-Paper-05_Hierarchical RL/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="META-LEARNING-SHARED-HIERARCHIES"><a href="#META-LEARNING-SHARED-HIERARCHIES" class="headerlink" title="META LEARNING SHARED HIERARCHIES"></a>META LEARNING SHARED HIERARCHIES</h2><p><em><a href="https://arxiv.org/pdf/1710.09767.pdf" target="_blank" rel="noopener">Paper Source</a></em><br><code>Journal:</code><br><code>Year: 2017</code><br><code>Institute: OpenAI</code><br><code>Author: Kevin Frans, Jonathan Ho, Xi Chen, Pieter Abbeel, John Schulman</code><br><code>#</code><em>Deep Reinforcement Learning</em> <code>#</code><em>Meta Learning</em> </p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/Elon-Musk.jpg" alt="Hugo">
          <p class="site-author-name" itemprop="name">Hugo</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">17</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/Huixxi" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.linkedin.com/in/uestc-hugo/" target="_blank" title="LinkedIn">
                  
                    <i class="fa fa-fw fa-linkedin"></i>
                  
                  LinkedIn
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/______HU______" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://stackoverflow.com/users/7121726/hu-xixi" target="_blank" title="Stackoverflow">
                  
                    <i class="fa fa-fw fa-stack-overflow"></i>
                  
                  Stackoverflow
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hugo</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/VEN/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/VEN/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/VEN/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/VEN/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/VEN/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/VEN/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.2"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.2"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'hugo-818';
      var disqus_identifier = 'index.html';
      var disqus_title = "";
      var disqus_url = '';

      function run_disqus_script(disqus_script){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');
      
    </script>
  




  
  

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  

</body>
</html>
